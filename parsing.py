import os

import requests
from bs4 import BeautifulSoup

BASE_URL = "https://www.president.gov.ua"
ORIGINAL_URL = BASE_URL + "/news/speeches"
WAYBACK_API = "https://archive.org/wayback/available"
SAVE_DIR = "speeches_texts"
os.makedirs(SAVE_DIR, exist_ok=True)


def get_latest_snapshot_url(target_url):
    params = {"url": target_url}
    res = requests.get(WAYBACK_API, params=params)
    data = res.json()
    try:
        return data["archived_snapshots"]["closest"]["url"]
    except KeyError:
        print("‚ùå Snapshot not found.")
        return None

def get_article_links_from_snapshot(snapshot_url):
    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞: {snapshot_url}")
    res = requests.get(snapshot_url)
    soup = BeautifulSoup(res.text, "html.parser")

    links = []
    for a in soup.select("div.item_stat.cat_stat h3 a[href]"):
        href = a["href"]
        if not href.startswith("http"):
            href = BASE_URL + href
        links.append(href)

    return links

def extract_filename_from_url(url):
    return url.split("/")[-1].split("?")[0] + ".txt"

def parse_speech(url):
    try:
        filename = extract_filename_from_url(url)
        filepath = os.path.join(SAVE_DIR, filename)

        if os.path.exists(filepath):
            print(f"‚è≠ –ü—Ä–æ–ø—É—Å–∫–∞—é (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç): {filename}")
            return

        print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é: {url}")
        res = requests.get(url)
        soup = BeautifulSoup(res.text, "html.parser")

        article_div = soup.find("div", class_="article_content", itemprop="articleBody")
        if not article_div:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –±–ª–æ–∫–∞.")
            return

        paragraphs = article_div.find_all("p")
        full_text = "\n\n".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(full_text)

        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filepath}")
    except Exception as e:
        print(f"‚ùó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {url}: {e}")


if __name__ == "__main__":
    snapshot_url = get_latest_snapshot_url(ORIGINAL_URL)
    if snapshot_url:
        links = get_article_links_from_snapshot(snapshot_url)
        print(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫.")
        for link in links:
            parse_speech(link)
